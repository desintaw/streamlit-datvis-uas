# -*- coding: utf-8 -*-
"""Datvis_UAS (1) (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L6ZyflL3sLo7napmbEP5Ph5o2mY16GTd

1. LOAD DATA
"""

import pandas as pd

# 1. LOAD DATASET (FIX SEPARATOR)
file_name = 'nilai_gizi.csv'
df = pd.read_csv(file_name, sep=';')  # ← DEFAULT = koma

# 2. CEK NAMA KOLOM
print(df.columns)

# 3. BERSIHKAN NAMA KOLOM
df.columns = df.columns.str.strip()

# 4. PERBAIKI FORMAT DESIMAL
numeric_cols = ['Energy_kcal', 'Protein_g', 'Fat_g', 'Sugar_g', 'Carbohydrate_g', 'Sodium_mg']

for col in numeric_cols:
    df[col] = (
        df[col]
        .astype(str)
        .str.replace(',', '.', regex=False)
    )
    df[col] = pd.to_numeric(df[col], errors='coerce')
(df.head())

"""2. PREPROCESSING NUMERIK"""

numerical_cols = ['Energy_kcal', 'Protein_g', 'Fat_g', 'Sugar_g', 'Carbohydrate_g', 'Sodium_mg']
df_numeric = df[numerical_cols].copy()

missing_check = pd.DataFrame({
    'Kolom': numerical_cols,
    'Jumlah Missing': [df[col].isnull().sum() for col in numerical_cols]
})

missing_check

df_numeric_imputed = df_numeric.copy()

for col in numerical_cols:
    median_val = df_numeric_imputed[col].median()
    df_numeric_imputed[col] = df_numeric_imputed[col].fillna(median_val)

missing_check_after = pd.DataFrame({
    'Kolom': numerical_cols,
    'Jumlah Missing Setelah Imputasi': [
        df_numeric_imputed[col].isnull().sum() for col in numerical_cols
    ]
})

missing_check_after

outlier_summary = []

for col in numerical_cols:
    Q1 = df_numeric_imputed[col].quantile(0.25)
    Q3 = df_numeric_imputed[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    jumlah_outlier = df_numeric_imputed[
        (df_numeric_imputed[col] < lower) |
        (df_numeric_imputed[col] > upper)
    ].shape[0]

    outlier_summary.append([col, lower, upper, jumlah_outlier])

outlier_df = pd.DataFrame(
    outlier_summary,
    columns=['Kolom', 'Batas_Bawah', 'Batas_Atas', 'Jumlah_Outlier']
)

outlier_df

df_numeric_capped = df_numeric_imputed.copy()

for col in numerical_cols:
    Q1 = df_numeric_capped[col].quantile(0.25)
    Q3 = df_numeric_capped[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    df_numeric_capped[col] = df_numeric_capped[col].clip(lower, upper)

import pandas as pd
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_array = scaler.fit_transform(df_numeric_capped)

df_numeric_scaled = pd.DataFrame(
    scaled_array,
    columns=[f'{col}_scaled' for col in numerical_cols],
    index=df_numeric_capped.index
)

(df_numeric_scaled.head())

df_preprocessed_numeric = pd.concat(
    [df[['Food_Name', 'Label_Kesehatan']],
     df_numeric_capped,
     df_numeric_scaled],
    axis=1
)

df_preprocessed_numeric.head()

"""3. PREPROCESSING TEKS"""

text_col = 'Food_Text'
label_col = 'Label_Kesehatan'

df_text = df[[text_col, label_col]].copy()
df_text.head()

df_text['text_lower'] = df_text[text_col].str.lower()
df_text[['Food_Text', 'text_lower']].head()

df_text['tokens'] = df_text['text_lower'].str.split()
df_text[['text_lower', 'tokens']].head()

custom_stopwords = {'and', 'or', 'with', 'of', 'the'}

df_text['tokens_clean'] = df_text['tokens'].apply(
    lambda x: [word for word in x if word not in custom_stopwords]
)

df_text[['tokens', 'tokens_clean']].head()

df_text['clean_text'] = df_text['tokens_clean'].apply(lambda x: ' '.join(x))
df_text[['text_lower', 'clean_text']].head()

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer()
X_tfidf = tfidf.fit_transform(df_text['clean_text'])

tfidf_df = pd.DataFrame(
    X_tfidf.toarray(),
    columns=tfidf.get_feature_names_out()
)

tfidf_df.head()

from sklearn.feature_selection import mutual_info_classif

label_mapping = {
    "Kurang Sehat": 0,
    "Cukup Sehat": 1,
    "Sehat": 2
}

y = df_text[label_col].map(label_mapping)

# Pastikan tidak ada label kosong
df_valid = df_text.loc[y.notnull()]
X_valid = tfidf_df.loc[df_valid.index]
y_valid = y.loc[df_valid.index]

mi_scores = mutual_info_classif(
    X_valid,
    y_valid,
    random_state=42
)

mi_df = (
    pd.DataFrame({
        "Fitur": X_valid.columns,
        "Information_Gain": mi_scores
    })
    .sort_values(by="Information_Gain", ascending=False)
)

mi_df.head(10)

import numpy as np

corr_matrix = tfidf_df.corr().abs()

upper_triangle = corr_matrix.where(
    np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
)

high_corr_features = [
    column for column in upper_triangle.columns
    if any(upper_triangle[column] > 0.9)
]

tfidf_cbfs = tfidf_df.drop(columns=high_corr_features)

tfidf_cbfs.head()

df_text_final = pd.concat(
    [df_text[[label_col, 'clean_text']], tfidf_cbfs],
    axis=1
)

df_text_final.head()

df_numeric_final = df_numeric_capped.copy()
df_numeric_final['Label_Kesehatan'] = df['Label_Kesehatan'].values

df_text_features = tfidf_cbfs.copy()

df_integrated = pd.concat(
    [df_numeric_final.reset_index(drop=True),
     df_text_features.reset_index(drop=True)],
    axis=1
)

df_integrated.head()

import matplotlib.pyplot as plt

# Rata-rata Kandungprint("\n" + "=" * 70)
print("3. WORD CLOUD BERDASARKAN LEVEL PROTEIN")
print("=" * 70)

from wordcloud import WordCloud
import matplotlib.pyplot as plt

# Bagi makanan berdasarkan kuartil protein
protein_quartiles = pd.qcut(df_preprocessed_numeric['Protein_g'], 4,
                            labels=['Sangat Rendah', 'Rendah', 'Tinggi', 'Sangat Tinggi'])

fig, axes = plt.subplots(2, 2, figsize=(15, 10))

for idx, (quartile, ax) in enumerate(zip(['Sangat Rendah', 'Rendah', 'Tinggi', 'Sangat Tinggi'], axes.flatten())):
    # Ambil indeks untuk kuartil ini
    idx_quartile = protein_quartiles[protein_quartiles == quartile].index

    # Ambil clean_text untuk makanan di kuartil ini
    quartile_texts = df_text_final.loc[idx_quartile, 'clean_text'].dropna()

    if len(quartile_texts) > 0:
        all_text = ' '.join(quartile_texts.astype(str))

        if len(all_text.strip()) > 0:
            wc = WordCloud(
                width=400,
                height=300,
                background_color='white',
                colormap='viridis',
                max_words=50,
                contour_width=1,
                contour_color='steelblue'
            ).generate(all_text)

            ax.imshow(wc, interpolation='bilinear')
            ax.set_title(f'Protein: {quartile}\n({len(quartile_texts)} makanan)',
                        fontsize=11, fontweight='bold')
            ax.axis('off')

            # Tambahkan info statistik
            mean_protein = df_preprocessed_numeric.loc[idx_quartile, 'Protein_g'].mean()
            ax.text(0.5, -0.1, f'Rata-rata protein: {mean_protein:.1f}g',
                   transform=ax.transAxes, ha='center', fontsize=9,
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        else:
            ax.text(0.5, 0.5, 'Tidak ada data teks',
                   transform=ax.transAxes, ha='center', va='center')
            ax.set_title(f'Protein: {quartile}', fontsize=11, fontweight='bold')
            ax.axis('off')
    else:
        ax.text(0.5, 0.5, 'Tidak ada data',
               transform=ax.transAxes, ha='center', va='center')
        ax.set_title(f'Protein: {quartile}', fontsize=11, fontweight='bold')
        ax.axis('off')

plt.suptitle('WORD CLOUD BERDASARKAN LEVEL KANDUNGAN PROTEIN\n(Menggunakan Clean Text dari Preprocessing)',
             fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.show() # Rata-rata Kandungan Protein pada Berbagai Jenis Makanan (Bar Chart)
plt.figure(figsize=(8,5))
avg_protein = df.groupby("Food_Name")["Protein_g"].mean()

avg_protein.plot(kind="bar")
plt.title("Rata-rata Kandungan Protein pada Berbagai Jenis Makanan")
plt.xlabel("Kategori Makanan")
plt.ylabel("Protein (gram)")
plt.xticks(rotation=0)
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# =====================================================
# 1. GABUNGKAN DATA IDENTITAS + HASIL PREPROCESSING NUMERIK
# =====================================================
df_numeric_final = pd.concat(
    [
        df[["Food_Name", "Label_Kesehatan"]],
        df_numeric_capped
    ],
    axis=1
)

# =====================================================
# 2. AGREGASI PER MAKANAN (ANTI DUPLIKASI)
# =====================================================
df_food = (
    df_numeric_final
    .groupby(["Food_Name", "Label_Kesehatan"], as_index=False)[
        ["Sugar_g", "Sodium_mg"]
    ]
    .mean()
)

# =====================================================
# 3. RATA-RATA GULA & NATRIUM PER LABEL KESEHATAN
# =====================================================
avg_sugar_sodium = (
    df_food
    .groupby("Label_Kesehatan")[["Sugar_g", "Sodium_mg"]]
    .mean()
)

# =====================================================
# 4. VISUALISASI BAR CHART
# =====================================================
avg_sugar_sodium.plot(kind="bar", figsize=(8,5))

plt.title("Perbandingan Rata-rata Gula dan Natrium Berdasarkan Label Kesehatan")
plt.xlabel("Label Kesehatan")
plt.ylabel("Rata-rata Kandungan")
plt.xticks(rotation=0)
plt.legend(["Gula (g)", "Natrium (mg)"])
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# =====================================================
# 1. GABUNGKAN IDENTITAS + DATA NUMERIK HASIL PREPROCESSING
# =====================================================
df_numeric_final = pd.concat(
    [
        df[["Food_Name", "Label_Kesehatan"]],
        df_numeric_capped
    ],
    axis=1
)

# =====================================================
# 2. AGREGASI PER MAKANAN (ANTI DUPLIKASI)
# =====================================================
df_food = (
    df_numeric_final
    .groupby(["Food_Name", "Label_Kesehatan"], as_index=False)[
        ["Protein_g", "Fat_g"]
    ]
    .mean()
)

# =====================================================
# 3. SCATTER PLOT
# =====================================================
plt.figure(figsize=(7,5))
sns.scatterplot(
    data=df_food,
    x="Protein_g",
    y="Fat_g",
    hue="Label_Kesehatan",
    s=80
)

plt.title("Hubungan Kandungan Protein dan Lemak")
plt.xlabel("Protein (gram)")
plt.ylabel("Lemak (gram)")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(7,5))
plt.hist(df_numeric_capped["Energy_kcal"], bins=20)

plt.title("Distribusi Energi (Kalori) Makanan (Data Setelah Preprocessing)")
plt.xlabel("Energi (kcal)")
plt.ylabel("Frekuensi")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud

# Fungsi pembuat WordCloud per label
def plot_wordcloud(df, label, title):
    text = " ".join(
        df[df["Label_Kesehatan"] == label]["Food_Text"]
        .dropna()
        .astype(str)
    )

    if len(text.strip()) == 0:
        print(f"Tidak ada data teks untuk label: {label}")
        return

    wc = WordCloud(
        width=800,
        height=400,
        background_color="white",
        colormap="viridis"
    ).generate(text)

    plt.figure(figsize=(10,4))
    plt.imshow(wc)
    plt.axis("off")
    plt.title(title)
    plt.tight_layout()
    plt.show()

plot_wordcloud(df, "Sehat", "Word Cloud Makanan Sehat")
plot_wordcloud(df, "Cukup Sehat", "Word Cloud Makanan Cukup Sehat")
plot_wordcloud(df, "Kurang Sehat", "Word Cloud Makanan Kurang Sehat")

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import mutual_info_classif

# =====================================
# TF-IDF VECTORISATION
# =====================================
vectorizer = TfidfVectorizer(
    max_features=20,
    stop_words="english"
)

X = vectorizer.fit_transform(df["Food_Text"].astype(str))

# =====================================
# ENCODING LABEL (MULTI-CLASS)
# =====================================
label_mapping = {
    "Kurang Sehat": 0,
    "Cukup Sehat": 1,
    "Sehat": 2
}

y = df["Label_Kesehatan"].map(label_mapping)

# Pastikan tidak ada label kosong
valid_idx = y.notnull()
X_valid = X[valid_idx.values] # Fixed: Use .values to get the NumPy array
y_valid = y[valid_idx] # This is fine as y is a pandas Series

# =====================================
# HITUNG INFORMATION GAIN
# =====================================
ig = mutual_info_classif(
    X_valid,
    y_valid,
    random_state=42
)

# Ambil nama fitur
features = vectorizer.get_feature_names_out()

# Buat DataFrame hasil
ig_df = (
    pd.DataFrame({
        "Fitur": features,
        "Information_Gain": ig
    })
    .sort_values(by="Information_Gain", ascending=False)
)

ig_df

plt.figure(figsize=(8,5))
sns.barplot(
    data=ig_df,
    x="Information_Gain",
    y="Fitur"
)
plt.title("Fitur Teks Paling Berpengaruh Berdasarkan Information Gain (Multi-Class)")
plt.xlabel("Information Gain")
plt.ylabel("Fitur Teks")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Gabungkan identitas + data numerik preprocessing
df_numeric_final = pd.concat(
    [
        df[['Food_Name']],
        df_numeric_capped
    ],
    axis=1
)

# Agregasi per makanan (anti duplikasi)
nutrisi_mean = (
    df_numeric_final
    .groupby('Food_Name', as_index=False)[
        ['Energy_kcal', 'Protein_g', 'Fat_g', 'Sugar_g', 'Carbohydrate_g', 'Sodium_mg']
    ]
    .mean()
)

# Hitung korelasi
corr = nutrisi_mean[
    ['Energy_kcal', 'Protein_g', 'Fat_g', 'Sugar_g', 'Carbohydrate_g', 'Sodium_mg']
].corr()

# Visualisasi
plt.figure(figsize=(8,6))
sns.heatmap(
    corr,
    annot=True,
    cmap="coolwarm",
    fmt=".2f",
    square=True
)
plt.title("Korelasi Antar Kandungan Gizi Makanan")
plt.tight_layout()
plt.show()

top_fat = (
    df.groupby("Food_Name", as_index=False)["Fat_g"]
      .mean()
      .sort_values("Fat_g", ascending=False)
      .head(10)
)

plt.figure(figsize=(8,5))
plt.barh(top_fat["Food_Name"], top_fat["Fat_g"])
plt.xlabel("Lemak (gram)")
plt.title("Top 10 Makanan dengan Kandungan Lemak Tertinggi")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

top_sugar = (
    df.sort_values("Sugar_g", ascending=False)
      .head(10)
)

plt.figure(figsize=(8,5))
plt.barh(top_sugar["Food_Name"], top_sugar["Sugar_g"])
plt.xlabel("Gula (gram)")
plt.title("Top 10 Makanan dengan Kandungan Gula Tertinggi")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

top_sodium = (
    df.sort_values("Sodium_mg", ascending=False)
      .head(10)
)

plt.figure(figsize=(8,5))
plt.barh(top_sodium["Food_Name"], top_sodium["Sodium_mg"])
plt.xlabel("Natrium (mg)")
plt.title("Top 10 Makanan dengan Kandungan Natrium Tertinggi")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

top_protein = (
    df.sort_values("Protein_g", ascending=False)
      .head(10)
)

plt.figure(figsize=(8,5))
plt.barh(top_protein["Food_Name"], top_protein["Protein_g"])
plt.xlabel("Protein (gram)")
plt.title("Top 10 Makanan dengan Kandungan Protein Tertinggi")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

top_energy = (
    df.sort_values("Energy_kcal", ascending=False)
      .head(10)
)

plt.figure(figsize=(8,5))
plt.barh(top_energy["Food_Name"], top_energy["Energy_kcal"])
plt.xlabel("Energi (kcal)")
plt.title("Top 10 Makanan dengan Kalori Tertinggi")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

top_energy = (
    df.sort_values("Carbohydrate_g", ascending=False)
      .head(10)
)

plt.figure(figsize=(8,5))
plt.barh(top_energy["Food_Name"], top_energy["Carbohydrate_g"])
plt.xlabel("Karcohidrat (gram)")
plt.title("Top 10 Makanan dengan Karbohidrat Tertinggi")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

max_values = {
    "Lemak (g)": df["Fat_g"].max(),
    "Gula (g)": df["Sugar_g"].max(),
    "Protein (g)": df["Protein_g"].max(),
    "Natrium (mg)": df["Sodium_mg"].max(),
    "Energi (kcal)": df["Energy_kcal"].max()
}

plt.figure(figsize=(7,5))
plt.bar(max_values.keys(), max_values.values())
plt.title("Nilai Maksimum Kandungan Nutrisi")
plt.ylabel("Nilai")
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

print("TOP 10 MAKANAN (DATA PREPROCESSED) PER KATEGORI")

# Gunakan df_preprocessed_numeric untuk konsistensi
fig, axes = plt.subplots(3, 2, figsize=(15, 12))

# Protein - Sehat
sehat_high_protein = (
    df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == 'Sehat']
    .sort_values('Protein_g', ascending=False)
    .head(10)
)

axes[0, 0].barh(range(len(sehat_high_protein)), sehat_high_protein['Protein_g'],
               color='green', alpha=0.7)
axes[0, 0].set_yticks(range(len(sehat_high_protein)))
axes[0, 0].set_yticklabels([f"{name[:18]}..." if len(name) > 20 else name
                          for name in sehat_high_protein['Food_Name']], fontsize=9)
axes[0, 0].set_xlabel('Protein (g)')
axes[0, 0].set_title('TOP 10 PROTEIN - MAKANAN SEHAT', fontsize=11, fontweight='bold')
axes[0, 0].invert_yaxis()
axes[0, 0].grid(True, alpha=0.3, axis='x')

# Gula - Kurang Sehat
kurang_sehat_high_sugar = (
    df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == 'Kurang Sehat']
    .sort_values('Sugar_g', ascending=False)
    .head(10)
)

axes[0, 1].barh(range(len(kurang_sehat_high_sugar)), kurang_sehat_high_sugar['Sugar_g'],
               color='red', alpha=0.7)
axes[0, 1].set_yticks(range(len(kurang_sehat_high_sugar)))
axes[0, 1].set_yticklabels([f"{name[:18]}..." if len(name) > 20 else name
                          for name in kurang_sehat_high_sugar['Food_Name']], fontsize=9)
axes[0, 1].set_xlabel('Gula (g)')
axes[0, 1].set_title('TOP 10 GULA - MAKANAN KURANG SEHAT', fontsize=11, fontweight='bold')
axes[0, 1].invert_yaxis()
axes[0, 1].grid(True, alpha=0.3, axis='x')

# Lemak - Cukup Sehat
cukup_sehat_high_fat = (
    df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == 'Cukup Sehat']
    .sort_values('Fat_g', ascending=False)
    .head(10)
)

axes[1, 0].barh(range(len(cukup_sehat_high_fat)), cukup_sehat_high_fat['Fat_g'],
               color='orange', alpha=0.7)
axes[1, 0].set_yticks(range(len(cukup_sehat_high_fat)))
axes[1, 0].set_yticklabels([f"{name[:18]}..." if len(name) > 20 else name
                          for name in cukup_sehat_high_fat['Food_Name']], fontsize=9)
axes[1, 0].set_xlabel('Lemak (g)')
axes[1, 0].set_title('TOP 10 LEMAK - MAKANAN CUKUP SEHAT', fontsize=11, fontweight='bold')
axes[1, 0].invert_yaxis()
axes[1, 0].grid(True, alpha=0.3, axis='x')

# Karbohidrat - Sehat
sehat_high_carbo = (
    df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == 'Sehat']
    .sort_values('Carbohydrate_g', ascending=False)
    .head(10)
)

axes[1, 1].barh(range(len(sehat_high_carbo)), sehat_high_carbo['Carbohydrate_g'],
               color='green', alpha=0.7)
axes[1, 1].set_yticks(range(len(sehat_high_carbo)))
axes[1, 1].set_yticklabels([f"{name[:18]}..." if len(name) > 20 else name
                          for name in sehat_high_carbo['Food_Name']], fontsize=9)
axes[1, 1].set_xlabel('Karbohidrat (g)')
axes[1, 1].set_title('TOP 10 KARBOHIDRAT - MAKANAN SEHAT', fontsize=11, fontweight='bold')
axes[1, 1].invert_yaxis()
axes[1, 1].grid(True, alpha=0.3, axis='x')

# Energi - Kurang Sehat
kurang_sehat_high_energy = (
    df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == 'Kurang Sehat']
    .sort_values('Energy_kcal', ascending=False)
    .head(10)
)

axes[2, 0].barh(range(len(kurang_sehat_high_energy)), kurang_sehat_high_energy['Energy_kcal'],
               color='red', alpha=0.7)
axes[2, 0].set_yticks(range(len(kurang_sehat_high_energy)))
axes[2, 0].set_yticklabels([f"{name[:18]}..." if len(name) > 20 else name
                          for name in kurang_sehat_high_energy['Food_Name']], fontsize=9)
axes[2, 0].set_xlabel('Energi (kcal)')
axes[2, 0].set_title('TOP 10 ENERGI - MAKANAN KURANG SEHAT', fontsize=11, fontweight='bold')
axes[2, 0].invert_yaxis()
axes[2, 0].grid(True, alpha=0.3, axis='x')

# Natrium - Kurang Sehat
kurang_sehat_high_sodium = (
    df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == 'Kurang Sehat']
    .sort_values('Sodium_mg', ascending=False)
    .head(10)
)

axes[2, 1].barh(range(len(kurang_sehat_high_sodium)), kurang_sehat_high_sodium['Sodium_mg'],
               color='red', alpha=0.7)
axes[2, 1].set_yticks(range(len(kurang_sehat_high_sodium)))
axes[2, 1].set_yticklabels([f"{name[:18]}..." if len(name) > 20 else name
                          for name in kurang_sehat_high_sodium['Food_Name']], fontsize=9)
axes[2, 1].set_xlabel('Natrium (mg)')
axes[2, 1].set_title('TOP 10 NATRIUM - MAKANAN KURANG SEHAT', fontsize=11, fontweight='bold')
axes[2, 1].invert_yaxis()
axes[2, 1].grid(True, alpha=0.3, axis='x')

plt.suptitle('TOP 10 MAKANAN BERDASARKAN DATA YANG SUDAH DIPREPROCESSING',
             fontsize=14, fontweight='bold', y=1.02)
plt.tight_layout()
plt.show()

print("\n" + "=" * 70)
print("INSIGHT 3: POLA KANDUNGAN NUTRISI YANG MEMBEDAKAN KATEGORI")
print("=" * 70)

# Radar chart untuk profil nutrisi per kategori
fig = plt.figure(figsize=(14, 6))

# Normalisasi data untuk radar chart
categories = ['Sehat', 'Cukup Sehat', 'Kurang Sehat']
nutrients_for_radar = ['Protein_g', 'Fat_g', 'Sugar_g', 'Carbohydrate_g', 'Sodium_mg', 'Energy_kcal']
nutrient_labels = ['Protein', 'Lemak', 'Gula', 'Karbo', 'Natrium', 'Energi']

# Hitung rata-rata dan normalisasi ke skala 0-1
category_profiles = {}

for category in categories:
    subset = df_preprocessed_numeric[df_preprocessed_numeric['Label_Kesehatan'] == category]
    means = []
    for nutrient in nutrients_for_radar:
        means.append(subset[nutrient].mean())

    # Normalisasi min-max
    means_array = np.array(means)
    if means_array.max() - means_array.min() > 0:
        normalized = (means_array - means_array.min()) / (means_array.max() - means_array.min())
    else:
        normalized = np.zeros_like(means_array)

    category_profiles[category] = normalized

# Plot radar chart
ax1 = fig.add_subplot(121, polar=True)

# Sudut untuk setiap nutrisi
angles = np.linspace(0, 2*np.pi, len(nutrients_for_radar), endpoint=False).tolist()
angles += angles[:1]  # Tutup lingkaran

# Plot setiap kategori
for category, color in zip(categories, ['green', 'orange', 'red']):
    values = category_profiles[category].tolist()
    values += values[:1]  # Tutup lingkaran

    ax1.plot(angles, values, 'o-', linewidth=2, label=category, color=color)
    ax1.fill(angles, values, alpha=0.25, color=color)

ax1.set_xticks(angles[:-1])
ax1.set_xticklabels(nutrient_labels)
ax1.set_ylim(0, 1)
ax1.set_title('PROFIL NUTRISI NORMALISASI\n(Perbandingan Relatif)', fontsize=12, fontweight='bold', pad=20)
ax1.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
ax1.grid(True)

# Parallel coordinates plot
ax2 = fig.add_subplot(122)

# Sampel acak untuk menghindari overplotting
sample_size = min(100, len(df_preprocessed_numeric))
sample_df = df_preprocessed_numeric.sample(sample_size, random_state=42)

# Normalisasi untuk parallel coordinates
parallel_data = []
for nutrient in nutrients_for_radar:
    col_data = sample_df[nutrient].values
    if col_data.max() - col_data.min() > 0:
        normalized = (col_data - col_data.min()) / (col_data.max() - col_data.min())
    else:
        normalized = np.zeros_like(col_data)
    parallel_data.append(normalized)

parallel_data = np.array(parallel_data).T

# Warna berdasarkan kategori
colors_map = {'Sehat': 'green', 'Cukup Sehat': 'orange', 'Kurang Sehat': 'red'}
sample_colors = [colors_map[label] for label in sample_df['Label_Kesehatan']]

# Plot parallel coordinates
for i in range(len(parallel_data)):
    ax2.plot(range(len(nutrients_for_radar)), parallel_data[i],
            color=sample_colors[i], alpha=0.3, linewidth=0.5)

ax2.set_xticks(range(len(nutrients_for_radar)))
ax2.set_xticklabels(nutrient_labels, rotation=45, ha='right')
ax2.set_ylabel('Nilai Normalisasi (0-1)')
ax2.set_title('PARALLEL COORDINATES\n(Visualisasi Multi-Dimensi)', fontsize=12, fontweight='bold')
ax2.grid(True, alpha=0.3)

plt.suptitle('ANALISIS POLA MULTI-DIMENSI NUTRISI\nMengidentifikasi Karakteristik Unik Setiap Kategori',
             fontsize=14, fontweight='bold', y=1.05)
plt.tight_layout()
plt.show()

# INSIGHT POLA
print("\n INSIGHT POLA UNIK:")
print("-" * 50)

# Analisis pola dominan
for category in categories:
    profile = category_profiles[category]
    max_idx = np.argmax(profile)
    min_idx = np.argmin(profile)

    print(f"\n{category.upper()}:")
    print(f"  Nutrisi dominan: {nutrient_labels[max_idx]} (skor: {profile[max_idx]:.2f})")
    print(f"  Nutrisi terendah: {nutrient_labels[min_idx]} (skor: {profile[min_idx]:.2f})")

    # Analisis kombinasi
    if nutrient_labels[max_idx] in ['Protein', 'Karbo'] and profile[max_idx] > 0.7:
        print(f"  → Didominasi oleh nutrisi makro ({nutrient_labels[max_idx]})")
    elif nutrient_labels[max_idx] in ['Gula', 'Lemak', 'Natrium'] and profile[max_idx] > 0.7:
        print(f"  → Didominasi oleh nutrisi yang perlu dibatasi")

df.to_csv("data_dashboard.csv", index=False)